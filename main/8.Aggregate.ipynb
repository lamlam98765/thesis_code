{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "chdir('/Users/lananhnguyen/Desktop/thesis/thesis_code')\n",
    "import main.packages.unchain_chain as chain\n",
    "import main.packages.mine_generic as mine_g\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from dieboldmariano import dm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_infl = pd.read_csv('data/headline_forecast/head_infl_forecast.csv')\n",
    "head_infl_new = head_infl.loc[:, ['ar_110_h_1', 'ar_110_h_2', 'ar_110_h_3', 'ar_ols_h_1', 'ar_ols_h_2',\n",
    "       'ar_ols_h_3']]\n",
    "head_infl_new.to_csv('data/headline_forecast/head_infl_forecast.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_y_reals():\n",
    "    cats = [\"food\", \"energy\", \"neig\", \"services\"]\n",
    "    \n",
    "    concatenated_df = pd.DataFrame()\n",
    "\n",
    "    for cat in cats:\n",
    "        cat_df = mine_g.load_excel(f\"data/hicp_cat_raw/prc_hicp_{cat}.xlsx\", name = f\"hicp_{cat}\", subset=True, verbose=0)\n",
    "        #cat_df = cat_df[(cat_df.index > mine_g.train_test_split_date)]\n",
    "        concatenated_df = pd.concat([concatenated_df, cat_df], axis=1)\n",
    "    return concatenated_df\n",
    "\n",
    "def extract_forecast_model_h(forecast_all_cat_df, model, h):\n",
    "    \"\"\"\n",
    "    in 4 df, extract columns with model's name and horizon\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = rf\"^{model}_(?!l).*h_{h}\"\n",
    "    matching_cols = [col for col in forecast_all_cat_df.columns if re.search(pattern, col)]\n",
    "    df_specific_model_h = forecast_all_cat_df.loc[:, matching_cols]\n",
    "    return df_specific_model_h\n",
    "\n",
    "import os\n",
    "\n",
    "def concatenate_csv_files(folder_path):\n",
    "    \"\"\"\n",
    "    Concatenates CSV files in a folder column-wise into a single DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - folder_path (str): Path to the folder containing CSV files.\n",
    "\n",
    "    Returns:\n",
    "    - concatenated_df (DataFrame): Concatenated DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    concatenated_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through each CSV file\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Add each file's data as new columns in the concatenated DataFrame\n",
    "        concatenated_df = pd.concat([concatenated_df, df], axis=1)\n",
    "        concatenated_df = concatenated_df.loc[:, ~concatenated_df.columns.duplicated()]\n",
    "\n",
    "    return concatenated_df\n",
    "\n",
    "def transform_to_chained(y_unchain, y_real):\n",
    "    y_real = y_real[y_real.index <= \"2022-12-31\"]\n",
    "    dec_mask = y_real.index.month == 12\n",
    "    dec_data = y_real.where(dec_mask, other=np.nan)\n",
    "    dec_data.ffill(inplace=True)\n",
    "    dec_data = dec_data[dec_data.index > \"2015-12-31\"]\n",
    "    # chain data back:\n",
    "    y_chained = y_unchain * dec_data\n",
    "    return y_chained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real = take_y_reals()\n",
    "\n",
    "\n",
    "folder_path = \"data/forecast_results\"\n",
    "forecast_yoy_all_cat = concatenate_csv_files(folder_path)\n",
    "date_range = pd.date_range(start=mine_g.train_test_split_date + pd.DateOffset(months=1), end=mine_g.max_X_date, freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lananhnguyen/anaconda3/envs/thesis/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Users/lananhnguyen/anaconda3/envs/thesis/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Users/lananhnguyen/anaconda3/envs/thesis/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Users/lananhnguyen/anaconda3/envs/thesis/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# take the weights:\n",
    "weight_f = pd.read_excel('data/hicp_cat_raw/prc_hicp_weight_food.xlsx', sheet_name='Sheet 1', skiprows=7)\n",
    "weight_f = weight_f.iloc[1, :].to_frame().reset_index()\n",
    "weight_f.columns = weight_f.iloc[0]\n",
    "weight_f = weight_f[1:]\n",
    "weight_f.rename(columns={\"TIME\": \"date\", \"Germany\": 'weight_f'}, inplace=True)\n",
    "\n",
    "weight_e = pd.read_excel('data/hicp_cat_raw/prc_hicp_weight_energy.xlsx', sheet_name='Sheet 1', skiprows=7)\n",
    "weight_e = weight_e.iloc[1, :].to_frame().reset_index()\n",
    "weight_e.columns = weight_e.iloc[0]\n",
    "weight_e = weight_e[1:]\n",
    "weight_e.rename(columns={\"TIME\": \"date\", \"Germany\": 'weight_e'}, inplace=True)\n",
    "\n",
    "weight_n = pd.read_excel('data/hicp_cat_raw/prc_hicp_weight_neig.xlsx', sheet_name='Sheet 1', skiprows=7)\n",
    "weight_n = weight_n.iloc[1, :].to_frame().reset_index()\n",
    "weight_n.columns = weight_n.iloc[0]\n",
    "weight_n = weight_n[1:]\n",
    "weight_n.rename(columns={\"TIME\": \"date\", \"Germany\": 'weight_n'}, inplace=True)\n",
    "\n",
    "weight_s = pd.read_excel('data/hicp_cat_raw/prc_hicp_weight_services.xlsx', sheet_name='Sheet 1', skiprows=7)\n",
    "weight_s = weight_s.iloc[1, :].to_frame().reset_index()\n",
    "weight_s.columns = weight_s.iloc[0]\n",
    "weight_s = weight_s[1:]\n",
    "weight_s.rename(columns={\"TIME\": \"date\", \"Germany\": 'weight_s'}, inplace=True)\n",
    "\n",
    "weights = pd.concat([weight_f, weight_e, weight_n, weight_s], axis=1)\n",
    "weights = weights.loc[:, ~weights.columns.duplicated()]\n",
    "weights['date'] = weights['date'].astype(int)\n",
    "for col in weights.columns[1:]:\n",
    "    weights[col] = weights[col].astype(float)\n",
    "\n",
    "weights.loc[:, 'total'] = weights.iloc[:, 1:5].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prc_food_h_1', 'prc_food_h_2', 'prc_food_h_3', 'ridge_food_h_1',\n",
       "       'ridge_food_h_2', 'ridge_food_h_3', 'lasso_food_h_1', 'lasso_food_h_2',\n",
       "       'lasso_food_h_3', 'xgb_food_h_1', 'xgb_food_h_2', 'xgb_food_h_3',\n",
       "       'cb_ridge_lasso_food_h_1', 'cb_ridge_lasso_food_h_2',\n",
       "       'cb_ridge_lasso_food_h_3', 'cb_ridge_pcr_food_h_1',\n",
       "       'cb_ridge_pcr_food_h_2', 'cb_ridge_pcr_food_h_3',\n",
       "       'cb_ridge_prc_lasso_food_h_1', 'cb_ridge_prc_lasso_food_h_2',\n",
       "       'cb_ridge_prc_lasso_food_h_3', 'ar_1_food_h_1', 'ar_1_food_h_2',\n",
       "       'ar_1_food_h_3', 'prc_energy_h_1', 'prc_energy_h_2', 'prc_energy_h_3',\n",
       "       'ridge_energy_h_1', 'ridge_energy_h_2', 'ridge_energy_h_3',\n",
       "       'lasso_energy_h_1', 'lasso_energy_h_2', 'lasso_energy_h_3',\n",
       "       'xgb_energy_h_1', 'xgb_energy_h_2', 'xgb_energy_h_3',\n",
       "       'cb_ridge_lasso_energy_h_1', 'cb_ridge_lasso_energy_h_2',\n",
       "       'cb_ridge_lasso_energy_h_3', 'cb_ridge_pcr_energy_h_1',\n",
       "       'cb_ridge_pcr_energy_h_2', 'cb_ridge_pcr_energy_h_3',\n",
       "       'cb_ridge_prc_lasso_energy_h_1', 'cb_ridge_prc_lasso_energy_h_2',\n",
       "       'cb_ridge_prc_lasso_energy_h_3', 'ar_1_energy_h_1', 'ar_1_energy_h_2',\n",
       "       'ar_1_energy_h_3', 'prc_neig_h_1', 'prc_neig_h_2', 'prc_neig_h_3',\n",
       "       'ridge_neig_h_1', 'ridge_neig_h_2', 'ridge_neig_h_3', 'lasso_neig_h_1',\n",
       "       'lasso_neig_h_2', 'lasso_neig_h_3', 'xgb_neig_h_1', 'xgb_neig_h_2',\n",
       "       'xgb_neig_h_3', 'cb_ridge_lasso_neig_h_1', 'cb_ridge_lasso_neig_h_2',\n",
       "       'cb_ridge_lasso_neig_h_3', 'cb_ridge_pcr_neig_h_1',\n",
       "       'cb_ridge_pcr_neig_h_2', 'cb_ridge_pcr_neig_h_3',\n",
       "       'cb_ridge_prc_lasso_neig_h_1', 'cb_ridge_prc_lasso_neig_h_2',\n",
       "       'cb_ridge_prc_lasso_neig_h_3', 'ar_1_neig_h_1', 'ar_1_neig_h_2',\n",
       "       'ar_1_neig_h_3', 'prc_services_h_1', 'prc_services_h_2',\n",
       "       'prc_services_h_3', 'ridge_services_h_1', 'ridge_services_h_2',\n",
       "       'ridge_services_h_3', 'lasso_services_h_1', 'lasso_services_h_2',\n",
       "       'lasso_services_h_3', 'xgb_services_h_1', 'xgb_services_h_2',\n",
       "       'xgb_services_h_3', 'cb_ridge_lasso_services_h_1',\n",
       "       'cb_ridge_lasso_services_h_2', 'cb_ridge_lasso_services_h_3',\n",
       "       'cb_ridge_pcr_services_h_1', 'cb_ridge_pcr_services_h_2',\n",
       "       'cb_ridge_pcr_services_h_3', 'cb_ridge_prc_lasso_services_h_1',\n",
       "       'cb_ridge_prc_lasso_services_h_2', 'cb_ridge_prc_lasso_services_h_3',\n",
       "       'ar_1_services_h_1', 'ar_1_services_h_2', 'ar_1_services_h_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_yoy_all_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar_1\n",
      "prc\n",
      "xgb\n",
      "ridge\n",
      "lasso\n",
      "cb_ridge_pcr\n",
      "cb_ridge_prc_lasso\n",
      "cb_ridge_lasso\n"
     ]
    }
   ],
   "source": [
    "models = ['ar_1','prc','xgb','ridge', 'lasso', 'cb_ridge_pcr', 'cb_ridge_prc_lasso', 'cb_ridge_lasso']\n",
    "\n",
    "horizons = [1, 2, 3]\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    for h in horizons:\n",
    "        # get the categorical data:\n",
    "        new_df = extract_forecast_model_h(forecast_yoy_all_cat, model, h)\n",
    "        new_df.set_index(date_range, inplace=True)\n",
    "\n",
    "\n",
    "        # transform:\n",
    "        food_chained = chain.transform_back_chained(new_df.iloc[:, 0], y_real.iloc[:, 0])\n",
    "        food_unchain = chain.unchain_series(food_chained, y_real.iloc[:, 0])\n",
    "        energy_chained = chain.transform_back_chained(new_df.iloc[:, 1], y_real.iloc[:, 1])\n",
    "        energy_unchain = chain.unchain_series(energy_chained, y_real.iloc[:, 1])\n",
    "        neig_chained = chain.transform_back_chained(new_df.iloc[:, 2], y_real.iloc[:, 2])\n",
    "        neig_unchained = chain.unchain_series(neig_chained, y_real.iloc[:, 2])\n",
    "        services_chained = chain.transform_back_chained(new_df.iloc[:, 3], y_real.iloc[:, 3])\n",
    "        services_unchained = chain.unchain_series(services_chained, y_real.iloc[:, 3])\n",
    "\n",
    "        # take the products of respective category and weights\n",
    "        food_unchain.name = 'food_unchain'\n",
    "        food_unchain = food_unchain.to_frame()\n",
    "        food_unchain.loc[:, 'year'] = food_unchain.index.year\n",
    "        food_unchain\n",
    "        merged_df = pd.merge(food_unchain, weights, how='inner', left_on='year', right_on='date')\n",
    "        mul_food = merged_df.loc[:, 'food_unchain'].mul(merged_df.loc[:, 'weight_f'])\n",
    "\n",
    "        energy_unchain.name = 'e_unchain'\n",
    "        e_unchain = energy_unchain.to_frame()\n",
    "        e_unchain.loc[:, 'year'] = e_unchain.index.year\n",
    "        merged_df = pd.merge(e_unchain, weights, how='inner', left_on='year', right_on='date')\n",
    "        mul_e = merged_df.loc[:, 'e_unchain'].mul(merged_df.loc[:, 'weight_e'])\n",
    "\n",
    "\n",
    "        neig_unchained.name = 'n_unchain'\n",
    "        n_unchain = neig_unchained.to_frame()\n",
    "        n_unchain.loc[:, 'year'] = n_unchain.index.year\n",
    "        merged_df = pd.merge(n_unchain, weights, how='inner', left_on='year', right_on='date')\n",
    "        mul_n = merged_df.loc[:, 'n_unchain'].mul(merged_df.loc[:, 'weight_n'])\n",
    "\n",
    "        services_unchained.name = 's_unchain'\n",
    "        s_unchain = services_unchained.to_frame()\n",
    "        s_unchain.loc[:, 'year'] = s_unchain.index.year\n",
    "        merged_df = pd.merge(s_unchain, weights, how='inner', left_on='year', right_on='date')\n",
    "        mul_s = merged_df.loc[:, 's_unchain'].mul(merged_df.loc[:, 'weight_s'])\n",
    "\n",
    "        # take the sum of all product:\n",
    "        mul_sum = pd.concat([mul_food, mul_e, mul_n, mul_s], axis=1)\n",
    "        mul_sum.loc[:, 'hicp_unchained'] = mul_sum.sum(axis=1)/1000\n",
    "\n",
    "        date_range = pd.date_range(start=mine_g.train_test_split_date + pd.DateOffset(months=1), end=mine_g.max_X_date, freq='M')\n",
    "        mul_sum.set_index(date_range, inplace=True)\n",
    "\n",
    "        # chain the results:\n",
    "        y_real_hicp = mine_g.load_excel('data/hicp_all.xlsx', 'hicp_all', verbose=0)\n",
    "        hicp_chained_final = transform_to_chained(mul_sum.loc[:, 'hicp_unchained'], y_real_hicp.iloc[:, 0])\n",
    "\n",
    "        y_real_hicp.loc[:, 'last_y'] = y_real_hicp.iloc[:, 0].shift(12)\n",
    "        y_real_hicp = y_real_hicp[(y_real_hicp.index > mine_g.train_test_split_date) & (y_real_hicp.index <= mine_g.max_X_date)]\n",
    "\n",
    "        hicp_all_yoy = (hicp_chained_final/y_real_hicp.loc[:, 'last_y']-1)*100\n",
    "        hicp_all_yoy.name = f'{model}_h_{h}'   \n",
    "        forecast = pd.read_csv('data/headline_forecast/head_infl_forecast.csv')\n",
    "        new_forecast = pd.concat([forecast, hicp_all_yoy.reset_index(drop=True)], axis=1)\n",
    "\n",
    "        new_forecast.to_csv('data/headline_forecast/head_infl_forecast.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare OLS for headline and OLS from individual cat aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = pd.read_csv('data/headline_forecast/head_infl_forecast.csv')\n",
    "\n",
    "real_hicp_yoy = pd.read_csv('data/preprocessed/head_inflation.csv', parse_dates = True, index_col='date')\n",
    "real_hicp_yoy_test = real_hicp_yoy[(real_hicp_yoy.index > mine_g.train_test_split_date) & (real_hicp_yoy.index <= mine_g.max_X_date)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar_110_h_1\n",
      "(-1.6769896095002441, 0.0973070531150434)\n",
      "ar_1_h_1\n",
      "(-2.509296608379326, 0.014041352791209554)\n",
      "prc_h_1\n",
      "(-1.4256522443636404, 0.1577188484032771)\n",
      "xgb_h_1\n",
      "(3.8123072933860644, 0.00026353024678415)\n",
      "ridge_h_1\n",
      "(-1.3968662707348651, 0.16617756166952335)\n",
      "lasso_h_1\n",
      "(-1.1413650878717199, 0.2570003729897524)\n",
      "cb_ridge_pcr_h_1\n",
      "(-1.3968662707348651, 0.16617756166952335)\n",
      "cb_ridge_prc_lasso_h_1\n",
      "(-1.7739972942888729, 0.0797310027548146)\n",
      "cb_ridge_lasso_h_1\n",
      "(-1.5297925317532695, 0.12987056895192084)\n",
      "ar_110_h_2\n",
      "(-1.5284227334846807, 0.13020984156895388)\n",
      "ar_1_h_2\n",
      "(-1.750981973746627, 0.08364361496407262)\n",
      "prc_h_2\n",
      "(-1.1162976528397033, 0.2675160514289605)\n",
      "xgb_h_2\n",
      "(2.4849772600907745, 0.014964546962963033)\n",
      "ridge_h_2\n",
      "(-1.4633495035463375, 0.14714862078269397)\n",
      "lasso_h_2\n",
      "(-1.3160512355498044, 0.19178002248812587)\n",
      "cb_ridge_pcr_h_2\n",
      "(-1.4633495035463375, 0.14714862078269397)\n",
      "cb_ridge_prc_lasso_h_2\n",
      "(-1.4572585234459576, 0.148818158199998)\n",
      "cb_ridge_lasso_h_2\n",
      "(-1.4974489086053977, 0.13806993137383872)\n",
      "ar_110_h_3\n",
      "(-1.4461771591154988, 0.15189327661093388)\n",
      "ar_1_h_3\n",
      "(-1.6056405285031052, 0.1121511789928008)\n",
      "prc_h_3\n",
      "(-1.304133559006359, 0.19579315163577482)\n",
      "xgb_h_3\n",
      "(-1.7345267972631382, 0.08653697440989602)\n",
      "ridge_h_3\n",
      "(-1.6610496772859413, 0.10047659310486212)\n",
      "lasso_h_3\n",
      "(-1.471672193670705, 0.14489098940125256)\n",
      "cb_ridge_pcr_h_3\n",
      "(-1.6610496772859413, 0.10047659310486212)\n",
      "cb_ridge_prc_lasso_h_3\n",
      "(-1.5491315804656376, 0.1251548656580651)\n",
      "cb_ridge_lasso_h_3\n",
      "(-1.6035271804244913, 0.11261717168331531)\n"
     ]
    }
   ],
   "source": [
    "rmse = []\n",
    "\n",
    "for h in [1, 2, 3]:\n",
    "    h_cols = []\n",
    "\n",
    "    for col in forecast.columns:\n",
    "        if col.endswith(str(h)):\n",
    "            h_cols.append(col)\n",
    "    forecast_df_h = forecast[h_cols]\n",
    "    \n",
    "    for col in [ col for col in forecast_df_h.columns if \"ar_ols\" not in col]:\n",
    "        print(col)\n",
    "        print(dm_test(real_hicp_yoy_test.iloc[:, 0], forecast_df_h[col], forecast_df_h.loc[:, f'ar_ols_h_{h}'], h = h, harvey_correction=True))\n",
    "\n",
    "\n",
    "    for col in forecast_df_h.columns:\n",
    "        rmse_here = np.sqrt(mean_squared_error(forecast_df_h[col], real_hicp_yoy_test))\n",
    "        rmse.append(rmse_here)\n",
    "\n",
    "\n",
    "def get_first_part(col_name, separator='_h'):\n",
    "    return col_name.split(separator)[0]\n",
    "\n",
    "new_col_names = [get_first_part(col) for col in forecast_df_h.columns]\n",
    "rmse = pd.DataFrame(rmse)\n",
    "rmse = pd.DataFrame(rmse.values.reshape(3, int(len(forecast.columns)/3)), columns=new_col_names, index=[f'h_{h}' for h in [1, 2, 3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ar_110</th>\n",
       "      <th>ar_ols</th>\n",
       "      <th>ar_1</th>\n",
       "      <th>prc</th>\n",
       "      <th>xgb</th>\n",
       "      <th>ridge</th>\n",
       "      <th>lasso</th>\n",
       "      <th>cb_ridge_pcr</th>\n",
       "      <th>cb_ridge_prc_lasso</th>\n",
       "      <th>cb_ridge_lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>h_1</th>\n",
       "      <td>0.626385</td>\n",
       "      <td>0.696370</td>\n",
       "      <td>0.666286</td>\n",
       "      <td>0.595058</td>\n",
       "      <td>1.108621</td>\n",
       "      <td>0.604577</td>\n",
       "      <td>0.625565</td>\n",
       "      <td>0.604577</td>\n",
       "      <td>0.584246</td>\n",
       "      <td>0.601347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_2</th>\n",
       "      <td>0.883125</td>\n",
       "      <td>1.075871</td>\n",
       "      <td>1.013742</td>\n",
       "      <td>0.865649</td>\n",
       "      <td>1.299482</td>\n",
       "      <td>0.756373</td>\n",
       "      <td>0.819226</td>\n",
       "      <td>0.756373</td>\n",
       "      <td>0.780401</td>\n",
       "      <td>0.766179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_3</th>\n",
       "      <td>1.116769</td>\n",
       "      <td>1.431566</td>\n",
       "      <td>1.337457</td>\n",
       "      <td>1.080243</td>\n",
       "      <td>1.190141</td>\n",
       "      <td>0.928331</td>\n",
       "      <td>1.012402</td>\n",
       "      <td>0.928331</td>\n",
       "      <td>0.974572</td>\n",
       "      <td>0.952910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ar_110    ar_ols      ar_1       prc       xgb     ridge     lasso  \\\n",
       "h_1  0.626385  0.696370  0.666286  0.595058  1.108621  0.604577  0.625565   \n",
       "h_2  0.883125  1.075871  1.013742  0.865649  1.299482  0.756373  0.819226   \n",
       "h_3  1.116769  1.431566  1.337457  1.080243  1.190141  0.928331  1.012402   \n",
       "\n",
       "     cb_ridge_pcr  cb_ridge_prc_lasso  cb_ridge_lasso  \n",
       "h_1      0.604577            0.584246        0.601347  \n",
       "h_2      0.756373            0.780401        0.766179  \n",
       "h_3      0.928331            0.974572        0.952910  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse.to_csv(\"data/report_rmse/total.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[h_1    0.90\n",
       " h_2    0.82\n",
       " h_3    0.78\n",
       " dtype: float64,\n",
       " h_1    1.0\n",
       " h_2    1.0\n",
       " h_3    1.0\n",
       " Name: ar_ols, dtype: float64,\n",
       " h_1    0.96\n",
       " h_2    0.94\n",
       " h_3    0.93\n",
       " dtype: float64,\n",
       " h_1    0.85\n",
       " h_2    0.80\n",
       " h_3    0.75\n",
       " dtype: float64,\n",
       " h_1    1.59\n",
       " h_2    1.21\n",
       " h_3    0.83\n",
       " dtype: float64,\n",
       " h_1    0.87\n",
       " h_2    0.70\n",
       " h_3    0.65\n",
       " dtype: float64,\n",
       " h_1    0.90\n",
       " h_2    0.76\n",
       " h_3    0.71\n",
       " dtype: float64,\n",
       " h_1    0.87\n",
       " h_2    0.70\n",
       " h_3    0.65\n",
       " dtype: float64,\n",
       " h_1    0.84\n",
       " h_2    0.73\n",
       " h_3    0.68\n",
       " dtype: float64,\n",
       " h_1    0.86\n",
       " h_2    0.71\n",
       " h_3    0.67\n",
       " dtype: float64]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_comparative = [round(rmse[col]/rmse[f'ar_ols'], 2) for col in rmse.columns]\n",
    "rmse_comparative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
